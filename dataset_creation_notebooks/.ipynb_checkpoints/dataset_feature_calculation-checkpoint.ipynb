{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bf3698e-638c-4a2a-b605-8d0f830de46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from sklearn.cluster import KMeans\n",
    "import cv2\n",
    "from matplotlib.colors import rgb_to_hsv\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "5011e2c0-ef0a-42c9-a17c-44d13c50e888",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_symmetry_score(image_name):\n",
    "    merged_dataset_path = \"images\"\n",
    "\n",
    "    if \".png\" not in image_name:\n",
    "        local_file_name = f\"{merged_dataset_path}/{image_name}.png\"\n",
    "    else:\n",
    "        local_file_name = f\"{merged_dataset_path}/{image_name}\"\n",
    "        \n",
    "    image = cv2.imread(local_file_name)\n",
    "    \n",
    "    try:\n",
    "        # Convert to grayscale and split the image\n",
    "        #print(\"calculate_symmetry_score\")\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        height, width = gray_image.shape\n",
    "        left_half = gray_image[:, :width // 2]\n",
    "        right_half = cv2.flip(gray_image[:, width // 2:], 1)\n",
    "\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions that occur during conversion and processing\n",
    "        print(f\"An error occurred during image processing: {e}\")\n",
    "        return None\n",
    "\n",
    "    else:\n",
    "        # This block will be executed if no exception is raised in the try block\n",
    "        # Calculate histograms and symmetry score\n",
    "        hist_left = cv2.calcHist([left_half], [0], None, [256], [0, 256])\n",
    "        hist_right = cv2.calcHist([right_half], [0], None, [256], [0, 256])\n",
    "        \n",
    "        score = cv2.compareHist(hist_left, hist_right, cv2.HISTCMP_CORREL)\n",
    "        return score\n",
    "\n",
    "\n",
    "def classify_symmetry(score):\n",
    "    if not score:\n",
    "        return \"N/A\"\n",
    "    if score > 0.8:\n",
    "        return \"High Symmetry\"\n",
    "    elif score > 0.5:\n",
    "        return \"Moderate Symmetry\"\n",
    "    elif score > -0.5:\n",
    "        return \"Low Symmetry\"\n",
    "    else:\n",
    "        return \"Negative Symmetry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c5cac0f8-5697-465f-b203-93ae3ec31ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_use_of_space(image_name):\n",
    "    merged_dataset_path = \"images\"\n",
    "\n",
    "    if \".png\" not in image_name:\n",
    "        local_file_name = f\"{merged_dataset_path}/{image_name}.png\"\n",
    "    else:\n",
    "        local_file_name = f\"{merged_dataset_path}/{image_name}\"\n",
    "        \n",
    "    image = cv2.imread(local_file_name)\n",
    "    try:\n",
    "        # Convert the image to grayscale\n",
    "        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions that occur during conversion\n",
    "        print(f\"An error occurred while converting the image to grayscale: {e}\")\n",
    "        return None\n",
    "\n",
    "    try:\n",
    "        # Detect edges using Canny\n",
    "        edges = cv2.Canny(gray_image, 100, 200)\n",
    "    except Exception as e:\n",
    "        # Handle any exceptions that occur during edge detection\n",
    "        print(f\"An error occurred while detecting edges: {e}\")\n",
    "        return None\n",
    "\n",
    "    # Calculate the negative space ratio\n",
    "    total_pixels = gray_image.size\n",
    "    edge_pixels = np.count_nonzero(edges)\n",
    "    negative_space_ratio = (total_pixels - edge_pixels) / total_pixels\n",
    "\n",
    "    return negative_space_ratio\n",
    "\n",
    "def classify_use_of_space(negative_space_ratio):\n",
    "    if not negative_space_ratio:\n",
    "        return None\n",
    "    if negative_space_ratio > 0.8:\n",
    "        return \"High use of negative space\"\n",
    "    elif negative_space_ratio > 0.6:\n",
    "        return \"Moderate use of negative space\"\n",
    "    else:\n",
    "        return \"Low use of negative space\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5ec7e5da-4503-43c2-a043-56ab423c438f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import graycomatrix, graycoprops\n",
    "from skimage.color import rgb2gray\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "\n",
    "def extract_texture_features(image_path):\n",
    "    # Load image and convert to grayscale\n",
    "    path = f'images/{image_path}'\n",
    "    image = imread(path)\n",
    "    if len(image.shape) == 2:\n",
    "        print(\"The image is already in grayscale.\")\n",
    "        gray_image = image\n",
    "    elif image.shape[2] == 2:\n",
    "        # Assuming the first channel is the grayscale intensity\n",
    "        gray_image = image[:, :, 0]\n",
    "    elif image.shape[2] == 4:\n",
    "        # Assuming the first channel is the grayscale intensity\n",
    "        image = image[:,:,:3]\n",
    "        \n",
    "        gray_image = rgb2gray(image)\n",
    "        gray_image = (gray_image * 255).astype('uint8')\n",
    "    elif len(image.shape) == 4:\n",
    "        if image.shape[0] == 1:\n",
    "            \n",
    "            image_squeezed = np.squeeze(image)\n",
    "            print(image_squeezed.shape)\n",
    "            gray_image = rgb2gray(image_squeezed)\n",
    "            gray_image = (gray_image * 255).astype('uint8')\n",
    "\n",
    "    else:\n",
    "        \n",
    "        # Convert to grayscale\n",
    "        gray_image = rgb2gray(image)\n",
    "        gray_image = (gray_image * 255).astype('uint8')\n",
    "\n",
    "    # This block will \n",
    "    \n",
    "    # Compute GLCM\n",
    "    glcm = graycomatrix(gray_image, distances=[5], angles=[0], levels=256, symmetric=True, normed=True)\n",
    "    \n",
    "    # Compute texture features\n",
    "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
    "    dissimilarity = graycoprops(glcm, 'dissimilarity')[0, 0]\n",
    "    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
    "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
    "    correlation = graycoprops(glcm, 'correlation')[0, 0]\n",
    "    \n",
    "    return {\n",
    "        'contrast': contrast,\n",
    "        'dissimilarity': dissimilarity,\n",
    "        'homogeneity': homogeneity,\n",
    "        'energy': energy,\n",
    "        'correlation': correlation,\n",
    "    }\n",
    "\n",
    "def classify_texture(row, feature):\n",
    "    # Contrast\n",
    "    \n",
    "    if feature == 'contrast':\n",
    "        if row['contrast'] < 1000:\n",
    "            return 'Somewhat Smooth'\n",
    "        elif row['contrast'] < 1500:\n",
    "            return 'Moderately Rough'\n",
    "        else:\n",
    "            return 'Very Rough'\n",
    "        \n",
    "    # Dissimilarity\n",
    "    if feature == 'dissimilarity':\n",
    "        if row['dissimilarity'] < 10:\n",
    "            return 'Somewhat Fine'\n",
    "        elif row['dissimilarity'] < 20:\n",
    "            return 'Moderately Coarse'\n",
    "        else:\n",
    "            return 'Very Coarse'\n",
    "    \n",
    "    # Homogeneity\n",
    "    if feature == 'homogeneity':\n",
    "        if row['homogeneity'] > 0.2 and row['homogeneity'] < 0.6:\n",
    "            return 'Somewhat Homogeneous'\n",
    "        elif row['homogeneity'] > 0.6:\n",
    "            return 'Homogeneous'    \n",
    "        else:\n",
    "            return 'Heterogeneous'\n",
    "    \n",
    "    # Energy\n",
    "    if feature == 'energy':\n",
    "        if row['energy'] > 0.03 and row['energy'] < 0.2:\n",
    "            return 'Somewhat Uniform'\n",
    "        elif row['energy'] >= 0.2:\n",
    "            return 'Uniform'\n",
    "        else:\n",
    "            return 'Non-uniform'\n",
    "    \n",
    "    # Correlation\n",
    "    if feature == 'correlation':\n",
    "        if row['correlation'] > 0.8:\n",
    "            return 'Highly Linearly-related'\n",
    "        elif row['correlation'] > 0.6:\n",
    "            return 'Moderately Linearly-related'\n",
    "        else:\n",
    "            return 'Non-linearly-related'\n",
    "    \n",
    "    if feature not in ('contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation'):\n",
    "        return None\n",
    "\n",
    "\n",
    "def get_feature_column(row, feature):\n",
    "    textures_results = row['textures_results']\n",
    "    if feature not in ('contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation'):\n",
    "        return None\n",
    "    return textures_results[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "e726f455-385b-4d95-9d59-6f4bbf1cf1e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"meta_data_billboard.csv\",  header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2d78bf90-cb0e-4c67-97e4-239adf1b6e5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The image is already in grayscale.\n",
      "(220, 220, 3)\n",
      "The image is already in grayscale.\n",
      "The image is already in grayscale.\n",
      "The image is already in grayscale.\n"
     ]
    }
   ],
   "source": [
    "df['textures_results'] = df['image_name'].apply(extract_texture_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "322760be-577d-4e3b-988d-b46e976038b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['contrast'] = df.apply(lambda row: get_feature_column(row, 'contrast'), axis=1)\n",
    "df['contrast_classification'] = df.apply(lambda row: classify_texture(row, 'contrast'), axis=1)\n",
    "\n",
    "df['dissimilarity'] = df.apply(lambda row: get_feature_column(row, 'dissimilarity'), axis=1)\n",
    "df['dissimilarity_classification'] = df.apply(lambda row: classify_texture(row, 'dissimilarity'), axis=1)\n",
    "\n",
    "df['homogeneity'] = df.apply(lambda row: get_feature_column(row, 'homogeneity'), axis=1)\n",
    "df['homogeneity_classification'] = df.apply(lambda row: classify_texture(row, 'homogeneity'), axis=1)\n",
    "\n",
    "df['energy'] = df.apply(lambda row: get_feature_column(row, 'energy'), axis=1)\n",
    "df['energy_classification'] = df.apply(lambda row: classify_texture(row, 'energy'), axis=1)\n",
    "\n",
    "df['correlation'] = df.apply(lambda row: get_feature_column(row, 'correlation'), axis=1)\n",
    "df['correlation_classification'] = df.apply(lambda row: classify_texture(row, 'correlation'), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "30057f18-ba0d-4610-8b27-87a2cdb886c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred while converting the image to grayscale: OpenCV(4.7.0) /Users/xperience/GHA-OCV-Python/_work/opencv-python/opencv-python/opencv/modules/imgproc/src/color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df['use_space_score'] = df['image_name'].apply(analyze_use_of_space)\n",
    "df['use_space_classification'] = df['use_space_score'].apply(classify_use_of_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98525fd-c240-4449-bfaa-ae1af5587bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['simmetry_score'] = df['image_name'].apply(calculate_symmetry_score)\n",
    "df['simmetry_classification'] = df['simmetry_score'].apply(classify_symmetry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "4379797a-c699-454a-b62c-165ab8411737",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(f\"billboard_stats.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "39a45395-472d-46bd-af45-f627bce60ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'contrast': 3769.756532769557, 'dissimilarity': 32.38219873150106, 'homogeneity': 0.27097122291063436, 'energy': 0.193390882151188, 'correlation': 0.7187470728943037} 3769.756532769557\n",
      "{'contrast': 2174.6197251585622, 'dissimilarity': 27.470169133192382, 'homogeneity': 0.12198368632829351, 'energy': 0.024516164717686223, 'correlation': 0.3951020397458072} 2174.6197251585622\n",
      "{'contrast': 1525.0115614617941, 'dissimilarity': 21.676810631229237, 'homogeneity': 0.11803429154162083, 'energy': 0.015525305550632662, 'correlation': 0.7157688192171027} 1525.0115614617941\n",
      "{'contrast': 2861.724083184258, 'dissimilarity': 29.750380143112697, 'homogeneity': 0.12773500450754144, 'energy': 0.01765791487008077, 'correlation': 0.5964143075576506} 2861.724083184258\n",
      "{'contrast': 475.4624524312897, 'dissimilarity': 11.108202959830868, 'homogeneity': 0.2555748372603701, 'energy': 0.04016119037973316, 'correlation': 0.48108296629034847} 475.4624524312897\n",
      "{'contrast': 5590.005803880804, 'dissimilarity': 49.90057172557172, 'homogeneity': 0.07803958414038518, 'energy': 0.010783414230523357, 'correlation': 0.4557452960769925} 5590.005803880804\n",
      "{'contrast': 2183.3417547568706, 'dissimilarity': 21.456892177589854, 'homogeneity': 0.30556560997857307, 'energy': 0.06647936327403395, 'correlation': 0.692183163231549} 2183.3417547568706\n",
      "{'contrast': 802.0095223354233, 'dissimilarity': 13.332018416927898, 'homogeneity': 0.17937131732451128, 'energy': 0.018232516725898523, 'correlation': 0.8802477882086892} 802.0095223354233\n",
      "{'contrast': 3628.8237258782774, 'dissimilarity': 32.63500742206828, 'homogeneity': 0.15566584075643813, 'energy': 0.021486827146197134, 'correlation': 0.3316024314340599} 3628.8237258782774\n",
      "{'contrast': 1810.478732993197, 'dissimilarity': 16.789152494331063, 'homogeneity': 0.5311409791038186, 'energy': 0.43806034935994487, 'correlation': 0.8374204468160198} 1810.478732993197\n",
      "{'contrast': 5980.382044348296, 'dissimilarity': 45.03550027041644, 'homogeneity': 0.0874637432056343, 'energy': 0.009085438701610752, 'correlation': 0.45553193158247823} 5980.382044348296\n",
      "{'contrast': 5496.104876219055, 'dissimilarity': 44.624306076519126, 'homogeneity': 0.1036809501734269, 'energy': 0.018250963000773526, 'correlation': 0.3143448997123385} 5496.104876219055\n",
      "{'contrast': 2813.1739981961086, 'dissimilarity': 25.603685092127307, 'homogeneity': 0.28583872542355315, 'energy': 0.11253615608416244, 'correlation': 0.7458344076782052} 2813.1739981961086\n",
      "{'contrast': 2080.348096099199, 'dissimilarity': 22.66921208989925, 'homogeneity': 0.3294156492818325, 'energy': 0.21226157526057085, 'correlation': 0.7657057098709235} 2080.348096099199\n",
      "{'contrast': 6947.391477198909, 'dissimilarity': 57.30016889697285, 'homogeneity': 0.05201411500189915, 'energy': 0.009029650904355192, 'correlation': 0.4805311425312105} 6947.391477198909\n",
      "{'contrast': 5236.420299681335, 'dissimilarity': 40.14141975727168, 'homogeneity': 0.2529428351853877, 'energy': 0.1376041216562819, 'correlation': 0.728030031128115} 5236.420299681335\n",
      "{'contrast': 4416.884434298759, 'dissimilarity': 39.63509773148809, 'homogeneity': 0.23585305655232702, 'energy': 0.09052968141401022, 'correlation': 0.44909828245540995} 4416.884434298759\n",
      "{'contrast': 3410.484968472439, 'dissimilarity': 34.5349515221371, 'homogeneity': 0.15280774465119415, 'energy': 0.03241307731681481, 'correlation': 0.5846176513038465} 3410.484968472439\n",
      "{'contrast': 3556.688012684989, 'dissimilarity': 31.522980972515853, 'homogeneity': 0.1487624267433283, 'energy': 0.03518001211952414, 'correlation': 0.7386906964400285} 3556.688012684989\n",
      "{'contrast': 6111.53543231962, 'dissimilarity': 49.15985688729875, 'homogeneity': 0.09425094105451631, 'energy': 0.023400452313803673, 'correlation': 0.6635645684262718} 6111.53543231962\n"
     ]
    }
   ],
   "source": [
    "for index, row in df[:20].iterrows():\n",
    "    textures_results = row['textures_results']\n",
    "    #print(textures_results, textures_results['contrast'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d51649-38c4-46fa-9a2d-fe02bed00652",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
